{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a4a1544-f4c0-4c1a-9eb5-4be2a70474ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "class ConverseAgent:\n",
    "    def __init__(self, model_id, region='us-west-2', system_prompt='You are a helpful assistant.'):\n",
    "        self.model_id = model_id\n",
    "        self.region = region\n",
    "        self.client = boto3.client('bedrock-runtime', region_name=self.region)\n",
    "        self.system_prompt = system_prompt\n",
    "        self.messages = []\n",
    "        self.tools = None\n",
    "        self.response_output_tags = [] # ['<response>', '</response>']\n",
    "\n",
    "    async def invoke_with_prompt(self, prompt):\n",
    "        content = [\n",
    "            {\n",
    "                'text': prompt\n",
    "            }\n",
    "        ]\n",
    "        return await self.invoke(content)\n",
    "\n",
    "    async def invoke(self, content):\n",
    "        print(f\"User: {json.dumps(content, indent=2)}\")\n",
    "\n",
    "        self.messages.append(\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": content\n",
    "            }\n",
    "        )\n",
    "        response = self._get_converse_response()\n",
    "\n",
    "        print(f\"Agent: {json.dumps(response, indent=2)}\")\n",
    "\n",
    "        return await self._handle_response(response)\n",
    "\n",
    "    def _get_converse_response(self):\n",
    "        \"\"\"\n",
    "        Invokes the Bedrock runtime converse API with proper configuration.\n",
    "        https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-runtime/client/converse.html\n",
    "        \"\"\"\n",
    "        # Prepare the request body\n",
    "        request_params = {\n",
    "            \"modelId\": self.model_id,\n",
    "            \"messages\": self.messages,\n",
    "            \"system\": [\n",
    "                {\n",
    "                    \"text\": self.system_prompt\n",
    "                }\n",
    "            ],\n",
    "            \"inferenceConfig\": {\n",
    "                \"maxTokens\": 8192,\n",
    "                \"temperature\": 0.7,\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Add tools if they exist\n",
    "        if self.tools:\n",
    "            tools_config = self.tools.get_tools()\n",
    "            if tools_config and tools_config.get('tools'):\n",
    "                request_params[\"toolConfig\"] = tools_config\n",
    "        \n",
    "        # Make the API call\n",
    "        response = self.client.converse(**request_params)\n",
    "        return response\n",
    "    \n",
    "    async def _handle_response(self, response):\n",
    "        # Add the response to the conversation history\n",
    "        self.messages.append(response['output']['message'])\n",
    "\n",
    "        # Process based on the stop reason\n",
    "        stop_reason = response['stopReason']\n",
    "\n",
    "        if stop_reason in ['end_turn', 'stop_sequence']:\n",
    "            # Extract text from the response\n",
    "            try:\n",
    "                message = response.get('output', {}).get('message', {})\n",
    "                content = message.get('content', [])\n",
    "                text = content[0].get('text', '')\n",
    "                \n",
    "                # Apply output tags if defined\n",
    "                if hasattr(self, 'response_output_tags') and len(self.response_output_tags) == 2:\n",
    "                    pattern = f\"(?s).*{re.escape(self.response_output_tags[0])}(.*?){re.escape(self.response_output_tags[1])}\"\n",
    "                    match = re.search(pattern, text)\n",
    "                    if match:\n",
    "                        return match.group(1)\n",
    "                return text\n",
    "            except (KeyError, IndexError):\n",
    "                return ''\n",
    "\n",
    "        elif stop_reason == 'tool_use':\n",
    "            try:\n",
    "                # Extract tool use details from response\n",
    "                tool_response = []\n",
    "                for content_item in response['output']['message']['content']:\n",
    "                    if 'toolUse' in content_item:\n",
    "                        tool_request = {\n",
    "                            \"toolUseId\": content_item['toolUse']['toolUseId'],\n",
    "                            \"name\": content_item['toolUse']['name'],\n",
    "                            \"input\": content_item['toolUse']['input']\n",
    "                        }\n",
    "                        \n",
    "                        # Execute the tool and add result to response\n",
    "                        tool_result = await self.tools.execute_tool(tool_request)\n",
    "                        tool_response.append({'toolResult': tool_result})\n",
    "                \n",
    "                # Continue the conversation with the tool results\n",
    "                return await self.invoke(tool_response)\n",
    "                \n",
    "            except KeyError as e:\n",
    "                raise ValueError(f\"Missing required tool use field: {e}\")\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Failed to execute tool: {e}\")\n",
    "\n",
    "        elif stop_reason == 'max_tokens':\n",
    "            # Hit token limit - ask model to continue\n",
    "            return await self.invoke_with_prompt('Please continue.')\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown stop reason: {stop_reason}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb92756f-c2a1-49b9-a173-12e8127a0afa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49f9040a-2aae-4b85-9da8-d5aff4158592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Callable\n",
    "import json\n",
    "\n",
    "class ConverseToolManager:\n",
    "    def __init__(self):\n",
    "        self._tools = {}\n",
    "        self._name_mapping = {}  # Maps sanitized names to original names\n",
    "    \n",
    "    def _sanitize_name(self, name: str) -> str:\n",
    "        \"\"\"Convert hyphenated names to underscore format for Bedrock compatibility\"\"\"\n",
    "        return name.replace('-', '_')\n",
    "    \n",
    "    def register_tool(self, name: str, func: Callable, description: str, input_schema: Dict):\n",
    "        \"\"\"\n",
    "        Register a new tool with the system, sanitizing the name for Bedrock compatibility\n",
    "        \"\"\"\n",
    "        sanitized_name = self._sanitize_name(name)\n",
    "        self._name_mapping[sanitized_name] = name\n",
    "        self._tools[sanitized_name] = {\n",
    "            'function': func,\n",
    "            'description': description,\n",
    "            'input_schema': input_schema,\n",
    "            'original_name': name\n",
    "        }\n",
    "        print(f\"Registered tool: {name} (sanitized as {sanitized_name})\")\n",
    "    \n",
    "    def get_tools(self) -> Dict[str, List[Dict]]:\n",
    "        tool_specs = []\n",
    "        for sanitized_name, tool in self._tools.items():\n",
    "            tool_specs.append({\n",
    "                'toolSpec': {\n",
    "                    'name': sanitized_name,\n",
    "                    'description': tool['description'],\n",
    "                    # Instead of passing the schema directly,\n",
    "                    # wrap it in the \"json\" field:\n",
    "                    'inputSchema': {\n",
    "                        'json': tool['input_schema']\n",
    "                    }\n",
    "                }\n",
    "            })\n",
    "    \n",
    "        return {'tools': tool_specs}\n",
    "    \n",
    "    async def execute_tool(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Execute a tool based on the agent's request, handling name translation\n",
    "        \"\"\"\n",
    "        tool_use_id = payload['toolUseId']\n",
    "        sanitized_name = payload['name']\n",
    "        tool_input = payload['input']\n",
    "        \n",
    "        if sanitized_name not in self._tools:\n",
    "            raise ValueError(f\"Unknown tool: {sanitized_name}\")\n",
    "        \n",
    "        try:\n",
    "            tool_func = self._tools[sanitized_name]['function']\n",
    "            # Use original name when calling the actual function via Smithery\n",
    "            original_name = self._tools[sanitized_name]['original_name']\n",
    "            \n",
    "            # Call the tool and get the result\n",
    "            result = await tool_func(original_name, tool_input)\n",
    "            \n",
    "            # Format the result for Bedrock converse API\n",
    "            return {\n",
    "                'toolUseId': tool_use_id,\n",
    "                'content': [{\n",
    "                    'text': json.dumps(result, indent=2)\n",
    "                }],\n",
    "                'status': 'success'\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'toolUseId': tool_use_id,\n",
    "                'content': [{\n",
    "                    'text': f\"Error executing tool: {str(e)}\"\n",
    "                }],\n",
    "                'status': 'error'\n",
    "            }\n",
    "    \n",
    "    def clear_tools(self):\n",
    "        \"\"\"Clear all registered tools\"\"\"\n",
    "        self._tools.clear()\n",
    "        self._name_mapping.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8c25444-ab08-4f77-ae3b-826b308c1c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import smithery\n",
    "import mcp.client.session\n",
    "\n",
    "from typing import Any, Dict\n",
    "\n",
    "class SmitheryToolManager(ConverseToolManager):\n",
    "    \"\"\"\n",
    "    Tool manager that knows how to execute tools via a Smithery (E2B) session,\n",
    "    rather than local Python functions.\n",
    "    \"\"\"\n",
    "    def __init__(self, session: mcp.client.session.ClientSession):\n",
    "        super().__init__()\n",
    "        self.session = session\n",
    "        \n",
    "    async def execute_tool(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Overridden to call Smithery (E2B) tools using our session,\n",
    "        rather than local Python function calls.\n",
    "        \"\"\"\n",
    "        tool_use_id = payload['toolUseId']\n",
    "        sanitized_name = payload['name']\n",
    "        tool_input = payload['input']\n",
    "        \n",
    "        if sanitized_name not in self._tools:\n",
    "            return {\n",
    "                'toolUseId': tool_use_id,\n",
    "                'content': [{\n",
    "                    'text': f\"Error: Unknown tool: {sanitized_name}\"\n",
    "                }],\n",
    "                'status': 'error'\n",
    "            }\n",
    "        \n",
    "        original_name = self._tools[sanitized_name]['original_name']\n",
    "        \n",
    "        try:\n",
    "            # Call the tool in E2B\n",
    "            tool_result = await self.session.call_tool(original_name, tool_input)\n",
    "            \n",
    "            # Convert to dict so we can JSON-serialize\n",
    "            tool_result_dict = tool_result.model_dump()\n",
    "            result_str = json.dumps(tool_result_dict, indent=2)\n",
    "            \n",
    "            return {\n",
    "                'toolUseId': tool_use_id,\n",
    "                'content': [{\n",
    "                    'text': result_str\n",
    "                }],\n",
    "                'status': 'success'\n",
    "            }\n",
    "        except Exception as e:\n",
    "            # In case E2B call failed\n",
    "            return {\n",
    "                'toolUseId': tool_use_id,\n",
    "                'content': [{\n",
    "                    'text': f\"Error executing tool: {str(e)}\"\n",
    "                }],\n",
    "                'status': 'error'\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94479073-23f8-43fc-9da0-80def7c260cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "\n",
    "import smithery\n",
    "import mcp.client.session\n",
    "\n",
    "# Assuming you've already defined:\n",
    "# - ConverseAgent\n",
    "# - SmitheryToolManager\n",
    "\n",
    "class MCPBedrockAgent(ConverseAgent):\n",
    "    \"\"\"\n",
    "    Bedrock-based agent that also integrates with Smithery (E2B)\n",
    "    for tool usage.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_id: str,\n",
    "        region: str = 'us-west-2',\n",
    "        system_prompt: str = 'You are a helpful assistant.'\n",
    "    ):\n",
    "        super().__init__(model_id=model_id, region=region, system_prompt=system_prompt)\n",
    "        # Create a smithery URL\n",
    "        self.url = smithery.create_smithery_url(\n",
    "            \"wss://server.smithery.ai/e2b/ws\", \n",
    "            {\"e2bApiKey\": \"e2b_ac1bb7a02f7ff62dbdd64f5875abe0c584e500e0\"}\n",
    "        )\n",
    "        \n",
    "    async def run_with_smithery(self, user_input: str) -> str:\n",
    "        \"\"\"\n",
    "        Example usage:\n",
    "          1. Open a Smithery session\n",
    "          2. Query the list of E2B tools\n",
    "          3. Register them with our SmitheryToolManager\n",
    "          4. Set that tool manager on the agent\n",
    "          5. Finally, do an `invoke_with_prompt` or `invoke` with user's input\n",
    "        \"\"\"\n",
    "        async with smithery.websocket_client(self.url) as streams:\n",
    "            async with mcp.client.session.ClientSession(*streams) as session:\n",
    "                # 1. List all Smithery Tools\n",
    "                tools_result = await session.list_tools()\n",
    "                # 'tools_result.model_dump()' is an MCP structure\n",
    "                e2b_tools = tools_result.model_dump()[\"tools\"]\n",
    "                \n",
    "                print(\"Available E2B tools:\", e2b_tools)\n",
    "                \n",
    "                # 2. Create a specialized tool manager for E2B\n",
    "                tool_manager = SmitheryToolManager(session=session)\n",
    "                \n",
    "                # 3. Register each tool from E2B with the manager\n",
    "                #    so that Bedrock can see them via 'get_tools()'.\n",
    "                for t in e2b_tools:\n",
    "                    # For Bedrock, we expect (name, description, inputSchema)\n",
    "                    # E2B returns them differently; let's unify field names:\n",
    "                    name = t[\"name\"]\n",
    "                    desc = t.get(\"description\", \"\")\n",
    "                    input_schema = t.get(\"inputSchema\", {})\n",
    "                    \n",
    "                    # Important: We're registering the tool manager's callback function\n",
    "                    # as a proxy that will handle calling the actual tool via E2B\n",
    "                    async def tool_proxy(original_name, tool_input):\n",
    "                        # This function will be called by ConverseToolManager.execute_tool\n",
    "                        # But will be ignored by SmitheryToolManager.execute_tool which overrides it\n",
    "                        return None\n",
    "                        \n",
    "                    tool_manager.register_tool(name, tool_proxy, desc, input_schema)\n",
    "                \n",
    "                # 4. Attach this tool manager to our agent\n",
    "                self.tools = tool_manager\n",
    "                \n",
    "                # 5. Now we can prompt the LLM; if it decides to use a tool,\n",
    "                #    the 'stop_reason=tool_use' flow in ConverseAgent will\n",
    "                #    route that call to SmitheryToolManager.execute_tool()\n",
    "                response_text = await self.invoke_with_prompt(user_input)\n",
    "                return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "890bddd0-e147-4f9c-9ea3-9ffe15d0b67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available E2B tools: [{'name': 'run_code', 'description': 'Run python code in a secure sandbox by E2B. Using the Jupyter Notebook syntax.', 'inputSchema': {'type': 'object', 'properties': {'code': {'type': 'string'}}, 'required': ['code'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}]\n",
      "Registered tool: run_code (sanitized as run_code)\n",
      "User: [\n",
      "  {\n",
      "    \"text\": \"Hello! Can you please do a sentiment analysis on this text: 'I love sunny days.'\"\n",
      "  }\n",
      "]\n",
      "Agent: {\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"a52f4b46-85e7-4151-a249-0214d4edb3a6\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"date\": \"Sat, 08 Mar 2025 08:48:56 GMT\",\n",
      "      \"content-type\": \"application/json\",\n",
      "      \"content-length\": \"1347\",\n",
      "      \"connection\": \"keep-alive\",\n",
      "      \"x-amzn-requestid\": \"a52f4b46-85e7-4151-a249-0214d4edb3a6\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  },\n",
      "  \"output\": {\n",
      "    \"message\": {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"text\": \"I'll help you perform a sentiment analysis on the text using Python. I'll use the NLTK library which is commonly used for natural language processing tasks, including sentiment analysis.\"\n",
      "        },\n",
      "        {\n",
      "          \"toolUse\": {\n",
      "            \"toolUseId\": \"tooluse_sVYrD1ktSw2D1DnNk979tw\",\n",
      "            \"name\": \"run_code\",\n",
      "            \"input\": {\n",
      "              \"code\": \"import nltk\\nfrom nltk.sentiment import SentimentIntensityAnalyzer\\n\\n# Download required NLTK data\\nnltk.download('vader_lexicon')\\n\\n# Create a SentimentIntensityAnalyzer object\\nsia = SentimentIntensityAnalyzer()\\n\\n# Text to analyze\\ntext = \\\"I love sunny days.\\\"\\n\\n# Perform sentiment analysis\\nsentiment_scores = sia.polarity_scores(text)\\n\\nprint(\\\"Sentiment Analysis Results:\\\")\\nprint(f\\\"Compound Score: {sentiment_scores['compound']}\\\")\\nprint(f\\\"Positive Score: {sentiment_scores['pos']}\\\")\\nprint(f\\\"Neutral Score: {sentiment_scores['neu']}\\\")\\nprint(f\\\"Negative Score: {sentiment_scores['neg']}\\\")\\n\\n# Interpret the compound score\\nif sentiment_scores['compound'] >= 0.05:\\n    print(\\\"\\\\nOverall Sentiment: Positive\\\")\\nelif sentiment_scores['compound'] <= -0.05:\\n    print(\\\"\\\\nOverall Sentiment: Negative\\\")\\nelse:\\n    print(\\\"\\\\nOverall Sentiment: Neutral\\\")\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"stopReason\": \"tool_use\",\n",
      "  \"usage\": {\n",
      "    \"inputTokens\": 449,\n",
      "    \"outputTokens\": 343,\n",
      "    \"totalTokens\": 792\n",
      "  },\n",
      "  \"metrics\": {\n",
      "    \"latencyMs\": 7407\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello! Can you please do a sentiment analysis on this text: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI love sunny days.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Let the agent open the E2B session, fetch tools, and handle conversation\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m agent\u001b[38;5;241m.\u001b[39mrun_with_smithery(user_input)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal response:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, response)\n",
      "Cell \u001b[0;32mIn[4], line 40\u001b[0m, in \u001b[0;36mMCPBedrockAgent.run_with_smithery\u001b[0;34m(self, user_input)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03mExample usage:\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m  1. Open a Smithery session\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m  5. Finally, do an `invoke_with_prompt` or `invoke` with user's input\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m smithery\u001b[38;5;241m.\u001b[39mwebsocket_client(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl) \u001b[38;5;28;01mas\u001b[39;00m streams:\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m mcp\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mClientSession(\u001b[38;5;241m*\u001b[39mstreams) \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;66;03m# 1. List all Smithery Tools\u001b[39;00m\n\u001b[1;32m     42\u001b[0m         tools_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m session\u001b[38;5;241m.\u001b[39mlist_tools()\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;66;03m# 'tools_result.model_dump()' is an MCP structure\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 75\u001b[0m, in \u001b[0;36mMCPBedrockAgent.run_with_smithery\u001b[0;34m(self, user_input)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtools \u001b[38;5;241m=\u001b[39m tool_manager\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# 5. Now we can prompt the LLM; if it decides to use a tool,\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m#    the 'stop_reason=tool_use' flow in ConverseAgent will\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m#    route that call to SmitheryToolManager.execute_tool()\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m response_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoke_with_prompt(user_input)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response_text\n",
      "Cell \u001b[0;32mIn[1], line 22\u001b[0m, in \u001b[0;36mConverseAgent.invoke_with_prompt\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke_with_prompt\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt):\n\u001b[1;32m     17\u001b[0m     content \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     18\u001b[0m         {\n\u001b[1;32m     19\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: prompt\n\u001b[1;32m     20\u001b[0m         }\n\u001b[1;32m     21\u001b[0m     ]\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoke(content)\n",
      "Cell \u001b[0;32mIn[1], line 37\u001b[0m, in \u001b[0;36mConverseAgent.invoke\u001b[0;34m(self, content)\u001b[0m\n\u001b[1;32m     33\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_converse_response()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson\u001b[38;5;241m.\u001b[39mdumps(response,\u001b[38;5;250m \u001b[39mindent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_response(response)\n",
      "Cell \u001b[0;32mIn[1], line 106\u001b[0m, in \u001b[0;36mConverseAgent._handle_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m     99\u001b[0m         tool_request \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    100\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoolUseId\u001b[39m\u001b[38;5;124m\"\u001b[39m: content_item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoolUse\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoolUseId\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    101\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: content_item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoolUse\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    102\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: content_item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoolUse\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    103\u001b[0m         }\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;66;03m# Execute the tool and add result to response\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m         tool_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtools\u001b[38;5;241m.\u001b[39mexecute_tool(tool_request)\n\u001b[1;32m    107\u001b[0m         tool_response\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoolResult\u001b[39m\u001b[38;5;124m'\u001b[39m: tool_result})\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# Continue the conversation with the tool results\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 38\u001b[0m, in \u001b[0;36mSmitheryToolManager.execute_tool\u001b[0;34m(self, payload)\u001b[0m\n\u001b[1;32m     34\u001b[0m original_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tools[sanitized_name][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# Call the tool in E2B\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m     tool_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mcall_tool(original_name, tool_input)\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# Convert to dict so we can JSON-serialize\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     tool_result_dict \u001b[38;5;241m=\u001b[39m tool_result\u001b[38;5;241m.\u001b[39mmodel_dump()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mcp/client/session.py:225\u001b[0m, in \u001b[0;36mClientSession.call_tool\u001b[0;34m(self, name, arguments)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_tool\u001b[39m(\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m, arguments: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    223\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m types\u001b[38;5;241m.\u001b[39mCallToolResult:\n\u001b[1;32m    224\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a tools/call request.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend_request(\n\u001b[1;32m    226\u001b[0m         types\u001b[38;5;241m.\u001b[39mClientRequest(\n\u001b[1;32m    227\u001b[0m             types\u001b[38;5;241m.\u001b[39mCallToolRequest(\n\u001b[1;32m    228\u001b[0m                 method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools/call\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    229\u001b[0m                 params\u001b[38;5;241m=\u001b[39mtypes\u001b[38;5;241m.\u001b[39mCallToolRequestParams(name\u001b[38;5;241m=\u001b[39mname, arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    230\u001b[0m             )\n\u001b[1;32m    231\u001b[0m         ),\n\u001b[1;32m    232\u001b[0m         types\u001b[38;5;241m.\u001b[39mCallToolResult,\n\u001b[1;32m    233\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mcp/shared/session.py:236\u001b[0m, in \u001b[0;36mBaseSession.send_request\u001b[0;34m(self, request, result_type)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m anyio\u001b[38;5;241m.\u001b[39mfail_after(\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_timeout_seconds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_timeout_seconds\u001b[38;5;241m.\u001b[39mtotal_seconds()\n\u001b[1;32m    235\u001b[0m     ):\n\u001b[0;32m--> 236\u001b[0m         response_or_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m response_stream_reader\u001b[38;5;241m.\u001b[39mreceive()\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m:\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m McpError(\n\u001b[1;32m    239\u001b[0m         ErrorData(\n\u001b[1;32m    240\u001b[0m             code\u001b[38;5;241m=\u001b[39mhttpx\u001b[38;5;241m.\u001b[39mcodes\u001b[38;5;241m.\u001b[39mREQUEST_TIMEOUT,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    246\u001b[0m         )\n\u001b[1;32m    247\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/anyio/streams/memory.py:109\u001b[0m, in \u001b[0;36mMemoryObjectReceiveStream.receive\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreceive\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T_co:\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m checkpoint()\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreceive_nowait()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/anyio/lowlevel.py:27\u001b[0m, in \u001b[0;36mcheckpoint\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheckpoint\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    Check for cancellation and allow the scheduler to switch to another task.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m get_async_backend()\u001b[38;5;241m.\u001b[39mcheckpoint()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/anyio/_backends/_asyncio.py:2319\u001b[0m, in \u001b[0;36mAsyncIOBackend.checkpoint\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m   2317\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   2318\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheckpoint\u001b[39m(\u001b[38;5;28mcls\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2319\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/asyncio/tasks.py:596\u001b[0m, in \u001b[0;36msleep\u001b[0;34m(delay, result)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Coroutine that completes after a given time (in seconds).\"\"\"\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m delay \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 596\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m __sleep0()\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    599\u001b[0m loop \u001b[38;5;241m=\u001b[39m events\u001b[38;5;241m.\u001b[39mget_running_loop()\n",
      "File \u001b[0;32m/usr/lib/python3.10/asyncio/tasks.py:590\u001b[0m, in \u001b[0;36m__sleep0\u001b[0;34m()\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;129m@types\u001b[39m\u001b[38;5;241m.\u001b[39mcoroutine\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sleep0\u001b[39m():\n\u001b[1;32m    583\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Skip one event loop run cycle.\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \n\u001b[1;32m    585\u001b[0m \u001b[38;5;124;03m    This is a private helper for 'asyncio.sleep()', used\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;124;03m    instead of creating a Future object.\u001b[39;00m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 590\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent = MCPBedrockAgent(\n",
    "        model_id=\"anthropic.claude-3-5-sonnet-20241022-v2:0\",  \n",
    "        region=\"us-west-2\",\n",
    "        system_prompt=\"You are a helpful assisatant with access to various tools.\"\n",
    "    )\n",
    "\n",
    "# Sample user input\n",
    "user_input = \"Hello! Can you please do a sentiment analysis on this text: 'I love sunny days.'\"\n",
    "\n",
    "# Let the agent open the E2B session, fetch tools, and handle conversation\n",
    "response = await agent.run_with_smithery(user_input)\n",
    "print(\"Final response:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70e89a44-e3c9-48af-9e0a-cfe06f94899d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'textarena' has no attribute 'make_online'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 19\u001b[0m\n\u001b[1;32m      5\u001b[0m agents \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;241m0\u001b[39m: MCPBedrockAgent(\n\u001b[1;32m      7\u001b[0m         model_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manthropic.claude-3-5-sonnet-20241022-v2:0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     )\n\u001b[1;32m     16\u001b[0m }\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Create and wrap the environment\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_online\u001b[49m(env_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimpleNegotiation-v0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m env \u001b[38;5;241m=\u001b[39m ta\u001b[38;5;241m.\u001b[39mwrappers\u001b[38;5;241m.\u001b[39mLLMObservationWrapper(env\u001b[38;5;241m=\u001b[39menv)\n\u001b[1;32m     21\u001b[0m env \u001b[38;5;241m=\u001b[39m ta\u001b[38;5;241m.\u001b[39mwrappers\u001b[38;5;241m.\u001b[39mSimpleRenderWrapper(\n\u001b[1;32m     22\u001b[0m     env\u001b[38;5;241m=\u001b[39menv,\n\u001b[1;32m     23\u001b[0m     player_names\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msonnet\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaiku\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     24\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'textarena' has no attribute 'make_online'"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import textarena as ta\n",
    "\n",
    "# Instantiate two distinct Bedrock agents\n",
    "agents = {\n",
    "    0: MCPBedrockAgent(\n",
    "        model_id=\"anthropic.claude-3-5-sonnet-20241022-v2:0\",\n",
    "        region=\"us-west-2\",\n",
    "        system_prompt=\"You are Agent 0 (sonnet). You are negotiating to get the best possible deal. Run the coding tools if it helps with your decision\"\n",
    "    ),\n",
    "    1: MCPBedrockAgent(\n",
    "        model_id=\"anthropic.claude-3-5-sonnet-20241022-v2:0\",\n",
    "        region=\"us-west-2\",\n",
    "        system_prompt=\"You are Agent 1 (haiku). You are negotiating to get the best possible deal.\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# Create and wrap the environment\n",
    "env = ta.make_online(env_id=\"SimpleNegotiation-v0\")\n",
    "env = ta.wrappers.LLMObservationWrapper(env=env)\n",
    "env = ta.wrappers.SimpleRenderWrapper(\n",
    "    env=env,\n",
    "    player_names={0: \"sonnet\", 1: \"haiku\"},\n",
    ")\n",
    "\n",
    "# Reset for two players\n",
    "env.reset(num_players=len(agents))\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "    # 1) The environment tells us which player's turn it is\n",
    "    #    and what that agent observes.\n",
    "    player_id, observation = env.get_observation()\n",
    "    \n",
    "    # 2) Pass that observation to the player's agent\n",
    "    #    and get back an \"action\" (a message, move, etc.).\n",
    "    #\n",
    "    #    NOTE: .run_with_smithery() is the method you showed\n",
    "    #    that opens a Smithery session, queries for tools,\n",
    "    #    and then calls invoke_with_prompt().\n",
    "    #    If you prefer a direct \"invoke\" call, adapt accordingly.\n",
    "    action = await agents[player_id].run_with_smithery(observation)\n",
    "    \n",
    "    # 3) Send that action to the environment\n",
    "    done, info = env.step(action=action)\n",
    "    print(\"step complete\")\n",
    "\n",
    "# Once done, retrieve final rewards or outcome\n",
    "rewards = env.close()\n",
    "print(\"Final Rewards:\", rewards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc12031-bbf6-4590-812c-5f4d104a0b94",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Agent' from 'textarena.core' (/home/kang5647/.local/lib/python3.10/site-packages/textarena/core.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01masyncio\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextarena\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Agent\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtextarena\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mta\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Agent' from 'textarena.core' (/home/kang5647/.local/lib/python3.10/site-packages/textarena/core.py)"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from textarena.core import Agent\n",
    "import textarena as ta\n",
    "from typing import Optional\n",
    "\n",
    "STANDARD_GAME_PROMPT = \"You are a competitive and reflective game player. Reflect deeply after each round, and use the best strategies to win. Make sure you read the game instructions carefully, and always follow the required format.\"\n",
    "\n",
    "class AsyncAnthropicAgent(Agent):\n",
    "    \"\"\"Agent class using the Anthropic Claude API to generate responses asynchronously.\"\"\"\n",
    "    def __init__(self, model_name: str, system_prompt: Optional[str] = STANDARD_GAME_PROMPT, max_tokens: int = 1000, temperature: float = 0.9, verbose: bool = False):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.system_prompt = system_prompt\n",
    "        self.max_tokens = max_tokens\n",
    "        self.temperature = temperature\n",
    "        self.verbose = verbose\n",
    "\n",
    "        try:\n",
    "            import anthropic\n",
    "        except ImportError:\n",
    "            raise ImportError(\n",
    "                \"Anthropic package is required for AsyncAnthropicAgent. \"\n",
    "                \"Install it with: pip install anthropic\"\n",
    "            )\n",
    "        self.client = anthropic.AsyncAnthropic()\n",
    "\n",
    "    async def _make_request(self, observation: str) -> str:\n",
    "        print(\"Making request\")\n",
    "        response = await self.client.messages.create(\n",
    "            model=self.model_name,\n",
    "            max_tokens=self.max_tokens,\n",
    "            temperature=self.temperature,\n",
    "            system=self.system_prompt,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": observation}]}\n",
    "            ]\n",
    "        )\n",
    "        print(response)\n",
    "        return response.content[0].text.strip()\n",
    "\n",
    "    async def _retry_request(self, observation: str, retries: int = 3, delay: int = 5) -> str:\n",
    "        last_exception = None\n",
    "        for attempt in range(1, retries + 1):\n",
    "            try:\n",
    "                response = await self._make_request(observation)\n",
    "                if self.verbose:\n",
    "                    print(f\"\\nObservation: {observation}\\nResponse: {response}\")\n",
    "                return response\n",
    "            except Exception as e:\n",
    "                last_exception = e\n",
    "                print(f\"Attempt {attempt} failed with error: {e}\")\n",
    "                if attempt < retries:\n",
    "                    await asyncio.sleep(delay)\n",
    "        raise last_exception\n",
    "\n",
    "    async def __call__(self, observation: str) -> str:\n",
    "        if not isinstance(observation, str):\n",
    "            raise ValueError(f\"Observation must be a string. Received type: {type(observation)}\")\n",
    "        return await self._retry_request(observation)\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    try:\n",
    "        model_name = \"Test LLM v7\"\n",
    "        model_description = \"Standard Anthropic model.\"\n",
    "        email = \"imaginecheckingemails@gmail.com\"\n",
    "\n",
    "        agent = AsyncAnthropicAgent(model_name=\"claude-3-7-sonnet-20250219\")\n",
    "\n",
    "        env = ta.make_online(\n",
    "            env_id=[\"SimpleNegotiation-v0\"],\n",
    "            model_name=model_name,\n",
    "            model_description=model_description,\n",
    "            email=email\n",
    "        )\n",
    "        env = ta.wrappers.LLMObservationWrapper(env=env)\n",
    "        env.reset(num_players=2)\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            player_id, observation = env.get_observation()\n",
    "            action = asyncio.get_event_loop().run_until_complete(agent(observation))\n",
    "            done, info = env.step(action=action)\n",
    "            print(\"Step complete\")\n",
    "\n",
    "        rewards = env.close()\n",
    "        print(\"Game finished. Rewards:\", rewards)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3ca65e-8372-4b3c-886a-7939f9c24f97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
